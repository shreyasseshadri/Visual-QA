{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "1oTTLJdilggV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b073b169-beeb-4505-8fc2-294c2285872f"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data #imported the required modules\n",
        "mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)#this loads the mnist data into tensorflow in one_hot encoding which encode categorial data into vector of number"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gxeW-9JBneoN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "one hot encoding converts data of categorial variables into binary vectors. ONLY 1 interger is marked 1 and rest are zero. eg: in 0-9 encoding '1' is encoded as  \"1=[0 1 0 0 0 0 0 0 0 0]\""
      ]
    },
    {
      "metadata": {
        "id": "2s-9wGxZoL7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_classes=10 #these are number of class labels\n",
        "batch_size=128 #it defines how many dimensions you will feed at a time \n",
        "x = tf.placeholder('float', [None, 784]) #this is the input placeholder\n",
        "y = tf.placeholder('float')# this is output placeholder, first dimension is non as batch defined it already"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TV-7ZdRErVGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#conv2d with input data and weight is used for convolution of input, window will move 1 pixel at a time \n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
        "#for finding the max in a window . Currently 2*2 window moves 2 pixels at a time\n",
        "def maxpool2d(x):\n",
        "    #                        size of window         movement of window\n",
        "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOQZIAnLscBc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You will padding equal to same which ensures that while performing the convolution operations, the boundary pixels of the image are not left out, so padding equal to same will basically adds zeros at the boundaries of the input and allow the convolution filter to access the boundary pixels as well."
      ]
    },
    {
      "metadata": {
        "id": "rWkLN0M-sytV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#function for cnn model implementation\n",
        "def convolutional_neural_network(x):\n",
        "    weights = {\n",
        "                'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),#1st hidden layer, weight with 5*5 convulation,1 input channel,32 output channels\n",
        "               'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),#2nd hidden layer, weight with 5*5 convlation, 32 input channel, 64 output channels\n",
        "               'W_fc':tf.Variable(tf.random_normal([7*7*64,1024])),# fully connected layer with 7*7*64 input and 1024 outputs\n",
        "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}# output layer with 10 output\n",
        "    #these have dimension according to each layer output channels\n",
        "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
        "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
        "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
        "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
        "    #reshape our input data to a 4d tensor\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "    \n",
        "    #convulation layer 1\n",
        "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])#rectified linear function to implement (input*weights)+ biases\n",
        "    conv1 = maxpool2d(conv1)#activation of layer and maxpool after convulation\n",
        "    #convulation layer 2\n",
        "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])#rectified linear function to implement (input*weights)+ biases\n",
        "    conv2 = maxpool2d(conv2)#activation of layer and maxpool after convulation\n",
        "    #fully connected layer\n",
        "    fc = tf.reshape(conv2,[-1, 7*7*64])#reshaping conv2 to fit fc layer\n",
        "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
        "   \n",
        "\n",
        "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
        "\n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYwz72ExxOpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#funtion for traning and testing the data\n",
        "def train_neural_network(x):\n",
        "  prediction = convolutional_neural_network(x)#prediction of output using our model\n",
        "   \n",
        "  cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )#comparing our output with actual output and finding the cost value\n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)  #using Adam optimizer(a famous deep learning optimization algo) to minimise the cost value\n",
        "    \n",
        "    #these are no. of cycle where each cycle->feed forward+backpropogation\n",
        "      epochs1 = 10\n",
        "    with tf.Session() as sess:   #this starts our tensorflow session\n",
        "        \n",
        "        sess.run(tf.initialize_all_variables())#intialize all the variable we declared above in our abstract\n",
        "\n",
        "        for epoch in range(epochs1):\n",
        "           #intialized as calculated in each interation\n",
        "           epoch_loss = 0\n",
        "          #dividing the dimension fed batchwise\n",
        "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "                #intialized for every batch size data\n",
        "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "                #cost is provided to optimizer and then cost is added to loss\n",
        "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
        "                epoch_loss += c\n",
        "\n",
        "          #printed to keep track of on cycle completion and cost after that \n",
        "          print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
        "        \n",
        "        #check correctness of our predicted output\n",
        "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "\n",
        "        #calculates accuracy by finding the mean over 'correct' values\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "      #print the accuaracy \n",
        "      print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
        "#funtion call for training the neural network model by passing data as argument\n",
        "train_neural_network(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}